# DuraGraph Python SDK Design Specification
# This document captures core design decisions for the SDK

metadata:
  version: "0.1.0"
  last_updated: "2024-12-29"
  status: draft

# =============================================================================
# CORE DESIGN DECISIONS
# =============================================================================

design_philosophy:
  approach: "Pythonic decorator-based API with Pydantic state"
  async_first: true
  type_safe: true

  principles:
    - Clean, intuitive API over compatibility
    - Async-first with optional sync wrappers
    - Pydantic for state validation and serialization
    - Decorator-based graph definition
    - LangGraph Cloud API compatibility (not SDK compatibility)

# =============================================================================
# STATE MODEL
# =============================================================================

state_model:
  primary: pydantic

  rationale:
    - Already a dependency in the project
    - Industry standard (FastAPI, LangChain, OpenAI SDK)
    - Catches errors at definition time, not runtime
    - Built-in serialization for checkpointing
    - IDE autocomplete support

  example: |
    from pydantic import BaseModel

    class AgentState(BaseModel):
        messages: list[str] = []
        tool_results: dict = {}
        final_answer: str | None = None

# =============================================================================
# GRAPH DEFINITION
# =============================================================================

graph_definition:
  style: decorator_based

  decorators:
    - "@Graph(id, state)" # Class decorator for graph definition
    - "@llm_node(model)"  # LLM call node
    - "@tool_node"        # Tool execution node
    - "@router_node"      # Conditional routing node
    - "@human_node"       # Human-in-the-loop node
    - "@entrypoint"       # Entry point node

  example: |
    @Graph(id="chat_agent", state=ChatState)
    class ChatAgent:

        @llm_node(model="gpt-4o-mini")
        async def think(self, state: ChatState) -> ChatState:
            return state.model_copy(update={"messages": state.messages + ["..."]})

        @router_node
        async def decide(self, state: ChatState) -> str:
            if state.tool_results:
                return "respond"
            return "search"

# =============================================================================
# ASYNC STRATEGY
# =============================================================================

async_strategy:
  primary: async
  sync_support: optional_wrappers

  rationale:
    - LLM calls are I/O-bound (network latency)
    - Enables parallel tool execution
    - Required for streaming responses
    - Modern Python best practice

  pattern: |
    # Primary API is async
    async def complete(self, messages) -> Response:
        ...

    # Sync wrapper for convenience (optional, added later if requested)
    def complete_sync(self, messages) -> Response:
        return asyncio.run(self.complete(messages))

# =============================================================================
# LANGGRAPH COMPATIBILITY
# =============================================================================

langgraph_compatibility:
  api_level: true   # Control plane is LangGraph Cloud API compatible
  sdk_level: false  # SDK has its own Pythonic API

  notes:
    - Control plane implements LangGraph Cloud REST API
    - SDK does NOT replicate LangGraph Python SDK patterns
    - Users can run existing LangGraph-style graphs via control plane
    - Native SDK uses cleaner decorator patterns

  future_consideration:
    adapter_layer: |
      # Potential future adapter for existing LangGraph code
      from duragraph.compat import from_langgraph
      graph = from_langgraph(existing_lg_graph)

# =============================================================================
# INTEGRATIONS ARCHITECTURE
# =============================================================================

integrations:
  location: sdk_only

  categories:
    llm_providers:
      - openai
      - anthropic
      - cohere (planned)
      - ollama (planned)

    vector_stores:
      - chroma
      - pinecone
      - weaviate (planned)
      - qdrant (planned)
      - pgvector (planned)

    knowledge_graphs:
      - neo4j (planned)
      - neptune (planned)
      - apache_age (planned)

    embeddings:
      - openai (planned)
      - cohere (planned)
      - sentence_transformers (planned)

  control_plane_integrations:
    - postgresql  # State storage only
    - nats        # Internal messaging only

  rationale:
    - Control plane stays simple (orchestration only)
    - No vendor lock-in for AI services
    - API keys stay with workers (security)
    - Users choose their providers

# =============================================================================
# PACKAGE STRUCTURE
# =============================================================================

package_structure:
  name: duragraph-python
  import_name: duragraph

  modules:
    - duragraph.graph      # Graph definition
    - duragraph.nodes      # Node decorators
    - duragraph.edges      # Edge definitions
    - duragraph.types      # Type definitions
    - duragraph.llm        # LLM providers
    - duragraph.vectorstores  # Vector store integrations
    - duragraph.embeddings # Embedding providers (planned)
    - duragraph.graphs     # Knowledge graph integrations (planned)
    - duragraph.tools      # Tool registry (planned)
    - duragraph.worker     # Worker for control plane
    - duragraph.cli        # CLI commands
    - duragraph.prompts    # Prompt management

# =============================================================================
# COMPARISON WITH OTHER FRAMEWORKS
# =============================================================================

framework_comparison:
  langgraph:
    similarity: low
    notes: "Different API style, but compatible control plane"

  langchain:
    similarity: low
    notes: "No LCEL pipe syntax, cleaner patterns"

  crewai:
    similarity: medium
    notes: "Both use decorator/class patterns, different focus"

  autogen:
    similarity: low
    notes: "Multi-agent conversation vs graph orchestration"

  dspy:
    similarity: low
    notes: "ML pipeline optimization vs workflow orchestration"
